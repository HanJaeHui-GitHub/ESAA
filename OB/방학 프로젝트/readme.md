# 2025년 천안시 데이터 분석 아이디어 경진대회

## 주제 : 천안시 노인 복지 사각지대 제로화를 위한 고위험군 예측 기반 정책 제안


[진행 현황]

### **1주차 주제 선정**

각 카테고리에 대한 현황 분석 후 천안시에 가장 유의미하다고 판단되는 주제 생각해오기

복지/사회 카테고리 담당

'복지 사각지대 고위험군 조기예측 시스템' 제안 > 선정됨

### **2주차 현황 분석**

'천안시 노인복지시설 분석' 담당
$\rightarrow$ 복지시설 증감 추세, 복지시설 위치 지도 시각화 진행

shapefile 형태 데이터 처음 사용해봄..!

### **3주차 데이터 수집 및 가공**
  
데이터 가공 & 세부지표 생성(모두), 데이터 병합 담당

유의미하게 해석될만한 지표 데이터 가공해서 만들기

* 데이터 병합시 읍면동 기준으로 병합 예정 $\rightarrow$ 동남구청, 서북구청 홈페이지 자료 크롤링 해서 기준 읍면동 선정

---
#### 데이터 가공

충청남도 **공간정보** 데이터 가공 진행

1. 충청남도_공간정보 노인대중교통접근성취약지역.csv

    columns : [공간정보(Multipolygon 형태), 공간 아이디, 남/여/연령대 구분 별 노인수]
    
    대중교통취약지역으로 선정된 지역에 어떤 성별, 어느 정도 나이의 노인이 몇명 거주하는지에 대한 데이터
    
    [가공 방법]
    
    Multipolygon 데이터를 이용해 중심 위경도 추출하여 열 추가
      
    중심 위경도를 이용하여 카카오 API를 통해 실주소로 매핑하여 실주소 열 추가(여기서 2시간 소요됨.. 12800개의 주소 변환이 생각보다 오래 걸림)
      
    실주소를 이용해 천안시만 필터링
      
    실주소에서 행정동과 법정리를 추출해서 해당 행정동+법정리에 노인수 count
      
    GIS 데이터를 기준 읍면동에 맞추어서 추출 $\leftarrow$ geometry, centroid, centroid_x, centroid_y
      
    대중교통취약노인이 존재하는 행정동 정보 매핑하여 최종 가공 데이터프레임 저장 후 지도 시각화 진행
    
2. 충청남도_공간정보 노인돌봄기본서비스수행기관.csv

   columns : [공간정보(POINT 형태), 시군구, 기관명, 주소]

   [가공 방법]

     시군구로 천안시 필터링 $\rightarrow$ 데이터 1개만 존재

     나중에 필요할 경우 그때 추출해서 사용하기로 결정

3. 충청남도_공간정보 노인복지시설.csv

   columns : [공간정보(POINT 형태), 구분, 시군, 기능, 이름, 주소]

   기능.unique()
   > (['양로시설', '노인공동생활가정', '노인요양시설(개정법)', '단기보호, 방문요양, 주야간보호',
       '방문목욕, 방문요양', '노인복지관', '주야간보호, 방문요양, 재가노인지원서비스', '방문요양',
       '노인요양공동생활가정', '주야간보호', '방문목욕, 방문요양, 재가노인지원서비스',
       '방문요양, 주야간보호, 재가노인지원서비스', '재가노인지원서비스',
       '방문목욕, 방문요양, 주야간보호, 재가노인지원서비스'], dtype=object)

   [가공 방법]

   시군을 이용해 천안시 필터링
   
   주소를 통해 행정동을 추출하여 기준 행정동 데이터에 병합

   기능별로 시설수 count

   기능별로 다른 도형으로 표시하여 지도 시각화 진행

4. 충청남도_공간정보 노인시설.csv

   columns : [시설구분, 시설명, 주소, 연락처]

   시설구분.unique()
   > (['노인요양시설', '경로식당', '노인요양공동생활가정', '재가노인복지시설 단기보호', '재가노인복지시설 방문목욕',
       '재가노인복지시설 방문요양', '재가노인복지시설 주야간보호', '단기보호', '방문요양', '주야간보호',
       '재가노인복지시설 재가노인지원서비스', '재가노인지원서비스', '양로시설', '공동생활가정', '방문목욕',
       '노인복지관'], dtype=object)

   [가공 방법]

   주소를 통해 천안시 필터링

   주소를 통해 행정동 추출하여 기준 행정동 데이터에 병합

   시설구분별로 시설수 count

5. 충청남도_공간정보 노인인구.csv

   columns : [공간정보(POINT 형태), 나이, 성별]

   [가공 방법]

   공간정보를 이용해 중심 위경도 추출하여 열 추가

   카카오 API를 이용해 역지오매핑하여 실주소 열 추가(6시간 소요..ㅜ.ㅜ, 57790개 데이터)

   실주소를 이용해 천안시 필터링

   실주소를 이용해서 기준 행정동 데이터에 맞춰 분류한 후 전체 노인수, 나이대별 노인수 count
   
---
#### 세부지표 생성

세부 지표명|산출 방식(피처 생성)|활용 데이터명|이유/비고
-|-|-|-
고령자 밀집도|고령자 비율을 구해 최대 고령자 비율 값으로 행정동별 고령자 비율 값을 나누어 고졍자 밀집도를 비교함|천안_동네별_인구수.csv|고령자의 밀집도 확인을 통해 복지 시설에 대한 수요수가 얼마인지 확인할 수 있음
복지시설 다양성 지수|복지시설 종류 수를 전체 종류 수로 나누어 계산함|천안시_노인시설.csv|다양한 방면에서 복지를 제공하고 있는지에 대한 확인이 가능함
교통 취약 노인수|행정동별 교통 취약 노인수 카운트|천안시_노인대중교통접근성취약지역.csv|교통 취약 지역의 노인수가 많을 수록 복지 사각지대 가능성 높다고 판단 가능
복지시설서비스 이용 잠재수요 지수|노인 인구수를 복지시설 수로 나누기|천안시_노인시설.csv|잠재 수요자가 많은 곳에 정책 제안 우선으로 하는게 좋을 것 같음

---
#### 다중매핑 구분

데이터 가공 당시 시간이 지나면서 행정동이 나누어지는 경우(ex. 쌍용동 $\rightarrow$ 쌍용 1,2,3동) 혹은 법정동 기준으로 생성되어 있는 데이터가 있어 중복 매핑 문제 존재!

시설 데이터 경우 위치 정보, 주소 정보가 존재하다는 것을 이용하여 **실제로 어느 행정동에 위치하는지 직접 확인하여** 재매핑하기로 결정

따라서 우리가 원하는 행정동 형태로 나뉘어 있는 위치 정보 파일 필요 $\rightarrow$ 전국구 행정동 geojson 파일 발견!!!!!

각 시설들의 실주소 -> 위경도 변환 진행 후 geojson 파일의 Multipolygon을 이용해 해당 위경도가 어느 행정동에 포함되는지 '정확행정동'으로 매핑하는 함수 제작하여 다중매핑 구분 성공

---
#### 데이터 병합

전체 병합
> (['구', '구분', '이름', '전체', '65세 이상', '고령화율(단위: 퍼센트)', '노인1천명당_재가복지시설수',
       '노인1천명당_주거복지시설수', '노인1천명당_의료복지시설수', '노인1천명당_여가복지시설수_경로당',
       '노인1천명당_여가복지시설수_노인교실', '노인1천명당_노인돌봄서비스수행기관수', '노인1천명당_무료급식소수',
       '노인1천명당_치매안심센터수', '노인1천명당_자립형일자리수행기관수', '고령자비율', '고령자밀집도지수',
       '복지시설다양성지수', '교통취약노인수', '복지서비스잠재수요지수', '사고건수', '보호구역 수', '기준연월',
       '월경제활동인구수_65_69', '월경제활동인구수_70세이상', '월대출평균잔액_65_69', '월대출평균잔액_70세이상',
       '월소득평균_65_69', '월소득평균_70세이상', '월신용평점평균_65_69', '월신용평점평균_70세이상',
       '월카드총이용금액평균_65_69', '월카드총이용금액평균_70세이상', '경제활동참가율_65_69',
       '경제활동참가율_70세이상', '고령인구수_65_69', '고령인구수_70세이상', '경제활동참가율_전체', '월소득평균',
       '월대출평균잔액', '월신용평점평균', '금융취약도지수', '국민기초생활보장_독거노인_수급자비율', '저소득_독거노인_비율',
       '일반_독거노인_비율', '국민기초생활보장_65\~79세_수급자비율', '국민기초생활보장_80세이상_수급자비율',
       '일반_65\~79세_비율', '일반_80세이상_비율', '저소득_65\~79세_비율', '저소득_80세이상_비율',
       '독거노인_합계', '독거노인_비율', '고령_1인가구수', '고령_비율', '계_증감', '계_2025', '계_2019',
       '65\~79세_2019', '80세 이상_2019'])

불필요 drop & 이름 변경 후
> (['구', '구분', '이름', '전체_인구', '65세 이상_인구', '고령화율', '노인1천명당_재가복지시설수',
       '노인1천명당_주거복지시설수', '노인1천명당_의료복지시설수', '노인1천명당_여가복지시설수_경로당',
       '노인1천명당_여가복지시설수_노인교실', '노인1천명당_노인돌봄서비스수행기관수', '노인1천명당_무료급식소수',
       '노인1천명당_치매안심센터수', '노인1천명당_자립형일자리수행기관수', '고령자비율', '고령자밀집도지수',
       '복지시설다양성지수', '교통취약노인수', '복지서비스잠재수요지수', '사고건수', '보호구역 수', '기준연월',
       '월경제활동인구수_65\~69세', '월경제활동인구수_70세이상', '월대출평균잔액_65\~69세', '월대출평균잔액_70세이상',
       '월소득평균_65\~69세', '월소득평균_70세이상', '월신용평점평균_65\~69세', '월신용평점평균_70세이상',
       '월카드총이용금액평균_65\~69세', '월카드총이용금액평균_70세이상', '경제활동참가율_65_69',
       '경제활동참가율_70세이상', '고령인구수_65_69', '고령인구수_70세이상', '경제활동참가율_전체', '월소득평균',
       '월대출평균잔액', '월신용평점평균', '금융취약도지수', '국민기초생활보장_독거노인_수급자비율', '저소득_독거노인_비율',
       '일반_독거노인_비율', '국민기초생활보장_65\~79세_수급자비율', '국민기초생활보장_80세이상_수급자비율',
       '일반_65\~79세_비율', '일반_80세이상_비율', '저소득_65\~79세_비율', '저소득_80세이상_비율',
       '독거노인_합계_2025', '독거노인_비율', '독거노인_증감인원수', '독거노인_합계_2019',
       '독거노인_65\~79세_2019', '독거노인_80세 이상_2019'])

### **4주차 분석 및 시각화**

---
#### 인자분석 실행

<인자 조합 선택 조건>

1. Bartlett 검정 : p-value가 0에 가까워 통계적으로 유의해야함. 즉, 변수들 간의 상관관계가 충분히 존재해야 함
2. KMO(Kaiser-Meyer-Olkin) 검사 : 최소 0.6 이상

인자 조합 선택 후 **n_factor, rotation, method** 조합을 어떻게 설정해야 비슷한 지표들끼리 인자로 묶일지 실험 진행

ㅁㅊ!!!!!!! 하루종일 3명이서 나눠서 하다가 회의하면서 잠깐 5분 돌렸는데 레전드 조합 탄생!!!! 내가 해냄!!!!!

```python
# drop 칼럼 선택(인자 수가 너무 많아서)
cols_to_drop = ['경제활동참가율', '사고건수', '보호구역 수','일반_독거노인_비율',
    '65세 이상_인구','독거노인_증감인원수', '저소득_독거노인_비율','복지시설다양성지수',
    '노인1천명당_의료복지시설수','노인1천명당_여가복지시설수_경로당',
    '월경제활동인구수','교통취약노인수','독거노인_합계','노인1천명당_주거복지시설수',
    '노인1천명당_노인돌봄서비스수행기관수' ] # VIF, 의미 생각하면서 결정
```

<조건 1>

(np.float64(590.0884608936556), np.float64(3.931827667052735e-74))

-이후 스케일링 진행-> (np.float64(601.9915592641623), np.float64(2.4792585869915832e-76))

<조건 2>

(np.float64(0.6097737020480162)

-이후 스케일링 진행-> np.float64(0.6077521794710167)

* 데이터 스케일링 진행해야한다는 사실을 망각.하고 있었음 이후 인자분석 코드 짜면서 스케일링

```python
# 데이터 정규화, 전처리
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np
import pandas as pd

# 원본 복사
processed = data.copy()

# === ① 로그 변환 대상 (금융 금액류: 금액 범위 큼) ===
log_vars = ['월대출평균잔액', '월소득평균', '월카드총이용금액평균']
for col in log_vars:
    processed[col] = processed[col].apply(lambda x: np.log1p(x))  # log(1 + x)

# === ② 스케일링 ===

# (1) StandardScaler 대상: 비율/지수류
standard_scale_vars = [
    '고령화율', '고령자밀집도지수', '금융취약도지수',
    '국민기초생활보장_독거노인_수급자비율', '독거노인_비율',
    '월신용평점평균'  # log 처리 포함
]
scaler_std = StandardScaler()
processed[standard_scale_vars] = scaler_std.fit_transform(processed[standard_scale_vars])

# (2) MinMaxScaler 대상: 시설 수 / 드물게 등장하는 정수형 변수
minmax_scale_vars = [
    '노인1천명당_재가복지시설수',
    '노인1천명당_여가복지시설수_노인교실',
    '노인1천명당_무료급식소수',
    '노인1천명당_치매안심센터수',
    '노인1천명당_자립형일자리수행기관수'
]
scaler_mm = MinMaxScaler()
processed[minmax_scale_vars] = scaler_mm.fit_transform(processed[minmax_scale_vars])

# (3) log + StandardScaler 대상: 금융 금액류
log_std_vars = ['월대출평균잔액', '월소득평균', '월카드총이용금액평균']
scaler_log_std = StandardScaler()
processed[log_std_vars] = scaler_log_std.fit_transform(processed[log_std_vars])

# === ③ 반전 처리 (고위험도에 음의 영향인 변수) ===
reverse_vars = [
    '노인1천명당_재가복지시설수',
    '노인1천명당_여가복지시설수_노인교실',
    '노인1천명당_무료급식소수',
    '노인1천명당_치매안심센터수',
    '노인1천명당_자립형일자리수행기관수',
    '월소득평균',
    '월신용평점평균',
    '월카드총이용금액평균'
]

# 1.0 - 값으로 뒤집기 (스케일링된 값 기준)
for col in reverse_vars:
    processed[col] = -processed[col]  # 또는 1.0 - processed[col] 도 가능

# 결과 확인
processed.head()
```

```python
# 인자분석 학습 조합
fa = FactorAnalyzer(n_factors = 5, rotation = 'varimax',method = 'ml').fit(data)
```

인자 1: 고령화 및 독거노인 특성(['고령화율', '고령자밀집도지수', '독거노인_비율'])

인자 2: 경제활동 및 소비여력(['월소득평균', '월신용평점평균', '월카드총이용금액평균'])

인자 3: 인지건강 서비스 지원(['노인1천명당_여가복지시설수_노인교실', '노인1천명당_치매안심센터수'])

인자 4: 금융취약도 및 부채부담(['금융취약도지수', '월대출평균잔액'])

인자 5: 취약 노인 생활 인프라(['노인1천명당_재가복지시설수', '노인1천명당_무료급식소수', '노인1천명당_자립형일자리수행기관수', '국민기초생활보장_독거노인_수급자비율'])

---
#### 인자분석

인자 분석 결과를 이용해 행정동별로 인자 점수, 점수, 점수(0~100) 계산

**이때 점수는 클수록 고위험에 가까움을 의미**

해당 데이터를 이용해 공간 자기상관성 분석 진행

1: HH (High-High) 대상 지점의 값이 높고, 주변 이웃들도 값이 높음 고값이 모여 있는 ‘핫스팟’ (Hot Spot)인 곳을 위험군으로 설정

위험군 데이터의 인자점수를 이용해 k=3(저,중,고)로 클러스터링 진행

cluster|인자1|인자2|인자3|인자4|인자5|점수|점수(0~100)
-|-|-|-|-|-|-|-
0|1.755929|-0.489304|-0.029140|-0.825806|0.478377|0.279001|77.068600
1|-0.040368|1.115880|-0.766326|0.035378|-0.718829|0.268481|76.247792
2|1.521519|0.069033|-0.088691|0.553548|0.613753|0.391993|85.884624
