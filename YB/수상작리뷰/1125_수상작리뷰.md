# 1125_수상작리뷰

### 데이터 주제 : **월간 데이콘 법원 판결 예측 AI 경진대회**

[https://dacon.io/en/competitions/official/236112/codeshare/8477?page=1&dtype=recent](https://dacon.io/en/competitions/official/236112/codeshare/8477?page=1&dtype=recent)

### 데이터

- **train.csv [파일]**
    
    ID : 사건 샘플 ID
    
    first_party : 사건의 첫 번째 당사자
    
    second_party : 사건의 두 번째 당사자
    
    facts : 사건 내용
    
    first_party_winner : 첫 번째 당사자의 승소 여부 (0 : 패배, 1 : 승리)
    
- **test.csv [파일]**
    
    ID : 사건 샘플 ID
    
    first_party : 사건의 첫 번째 당사자
    
    second_party : 사건의 두 번째 당사자
    
    facts : 사건 내용
    
- **sample_submission.csv [파일] - 제출 양식**
    
    ID : 사건 샘플 ID
    
    first_party_winner : 예측한 첫 번째 당사자의 승소 여부 (0 : 패배, 1 : 승리)
    

### 코드 흐름

텍스트 분류 모델과 언어 모델 결과를 종합함.

a. Text classification models (e.g., bert)

- class imbalance 문제 해결하기 위해 first party와 second party의 순서를 바꾸는 data augmentation 방법 적용.
- pretrained weights 부분은 모두 freeze 한 뒤 추가되는 residual connection이 적용된 네트워크 직접 설계.
- 텍스트 분류 모델 중 4가지 모델 활용.

b. Large language models (e.g., vicuna-13b)

- 예측해야 하는 테스트 데이터와 유사한 판결 사례들을 함께 활용하여 예측하는 few-shot learning 접근 방법 활용.
- ALBERT 기반 판결 내용을 하나의 embedding vector로 압축하여 유사한 판결 사례들을 cosine similarity 계산하여 선별.
- 언어 모델 중 Vicuna-13B 활용.

### 차별점, 배울점

- 데이터 전처리 방식이 독특함
    
    1. EDA & Back translation: 법원 판결 내용 자체가 일반 문서 데이터보다 난이도가 높아 어색한 변환 결과를 보았기 때문에 텍스트 수정 없이 원본 정보를 유지
    
    2. Over/under sampling: 초기 접근 방법은 first pary+second party+facts를 하나의 텍스트로 연결한 뒤 first party 승리 여부를 예측했으나 모델은 first party와 second party의 정보를 전혀 이용하지 않고 facts 내용 기반 승패를 예측하는 과적합 현상을 관측
    
    따라서 사건과 대상자가 직접적으로 연결될 수 있는 새로운 모델 구조 설계가 필요했고 이전 지식을 이용하여 first party와 second party의 위치를 섞는 모델을 도출해냄
    
- 하드웨어 스펙: A6000 x 1, RAM 252GB ← 왜 알려준걸까?
    
    사용한 언어 모델인 Vicuna-13B가 수십 GB의 GPU 메모리를 필요로 함
    
    사용되는 모델 중 매개변수가 많은 경우 GPU 메모리 사용량이 크기 때문에 하드웨어 스펙 또한 매우 중요함
